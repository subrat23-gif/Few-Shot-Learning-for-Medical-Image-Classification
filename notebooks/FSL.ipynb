{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44dd07fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing existing directory: fsl_data\n",
      "Creating new directory structure at: fsl_data\n",
      "Copying base classes (Normal, Pneumonia) to meta_train...\n",
      "Copying novel classes (COVID, TB) to meta_test...\n",
      "\n",
      "Data setup complete.\n",
      "Meta-Train (Base) classes in: fsl_data\\meta_train\n",
      "Meta-Test (Novel) classes in: fsl_data\\meta_test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# --- Configuration ---\n",
    "# This is the path to your current dataset (e.g., 'processed_data/')\n",
    "# It should contain 4 folders: 'COVID', 'Pneumonia', 'TB', 'Normal'\n",
    "SOURCE_DIR = r\"C:\\Users\\SUBRAT\\MAFSL PROJECT\\processed_data\\processed_data\"\n",
    "\n",
    "# These are the new directories we will create\n",
    "BASE_DIR = 'fsl_data'\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, 'meta_train')\n",
    "TEST_DIR = os.path.join(BASE_DIR, 'meta_test')\n",
    "\n",
    "# Define our class split\n",
    "# Base classes for meta-training\n",
    "BASE_CLASSES = ['Normal', 'Pneumonia']\n",
    "\n",
    "# Novel classes for meta-testing\n",
    "NOVEL_CLASSES = ['COVID', 'Tuberculosis']\n",
    "# ---------------------\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"\n",
    "    This function creates a new 'fsl_data' directory with a\n",
    "    'meta_train' and 'meta_test' split.\n",
    "    \n",
    "    WARNING: It will delete and replace 'fsl_data' if it already exists.\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.exists(BASE_DIR):\n",
    "        print(f\"Removing existing directory: {BASE_DIR}\")\n",
    "        shutil.rmtree(BASE_DIR)\n",
    "        \n",
    "    print(f\"Creating new directory structure at: {BASE_DIR}\")\n",
    "    os.makedirs(TRAIN_DIR, exist_ok=True)\n",
    "    os.makedirs(TEST_DIR, exist_ok=True)\n",
    "\n",
    "    # 1. Copy Base Classes to meta_train\n",
    "    print(\"Copying base classes (Normal, Pneumonia) to meta_train...\")\n",
    "    for cls in BASE_CLASSES:\n",
    "        src = os.path.join(SOURCE_DIR, cls)\n",
    "        dst = os.path.join(TRAIN_DIR, cls)\n",
    "        if os.path.exists(src):\n",
    "            shutil.copytree(src, dst)\n",
    "        else:\n",
    "            print(f\"  Warning: Source folder not found at {src}\")\n",
    "\n",
    "    # 2. Copy Novel Classes to meta_test\n",
    "    print(\"Copying novel classes (COVID, TB) to meta_test...\")\n",
    "    for cls in NOVEL_CLASSES:\n",
    "        src = os.path.join(SOURCE_DIR, cls)\n",
    "        dst = os.path.join(TEST_DIR, cls)\n",
    "        if os.path.exists(src):\n",
    "            shutil.copytree(src, dst)\n",
    "        else:\n",
    "            print(f\"  Warning: Source folder not found at {src}\")\n",
    "\n",
    "    print(\"\\nData setup complete.\")\n",
    "    print(f\"Meta-Train (Base) classes in: {TRAIN_DIR}\")\n",
    "    print(f\"Meta-Test (Novel) classes in: {TEST_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(SOURCE_DIR):\n",
    "        print(f\"Error: Source data directory not found at '{SOURCE_DIR}'\")\n",
    "        print(\"Please make sure your 'processed_data' folder is at that location.\")\n",
    "    else:\n",
    "        setup_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15793199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchxrayvision as xrv\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Model Definition ---\n",
    "class PrototypicalNet(nn.Module):\n",
    "    # --- THIS IS THE NEW CONSTRUCTOR ---\n",
    "    # It now accepts an 'out_dim' (output dimension)\n",
    "    def __init__(self, out_dim=256): \n",
    "        super(PrototypicalNet, self).__init__()\n",
    "        \n",
    "        full_model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
    "        self.backbone = full_model.features\n",
    "        \n",
    "        # --- SOLUTION 1: FREEZE THE BACKBONE ---\n",
    "        # We will trust its pre-trained weights as a powerful feature extractor\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # --- SOLUTION 1: ADD A SMALL, TRAINABLE EMBEDDING HEAD ---\n",
    "        # The optimizer will now *only* train these parameters (1024 -> 256)\n",
    "        # DenseNet-121 output is 1024 features\n",
    "        self.embedding_head = nn.Linear(1024, out_dim)\n",
    "\n",
    "    # --- UPDATED FORWARD METHOD ---\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # --- 1. Pass input through the *frozen* backbone ---\n",
    "        # We use torch.no_grad() to ensure no gradients are computed\n",
    "        with torch.no_grad(): \n",
    "            features = self.backbone(x)\n",
    "            \n",
    "        pooled = self.pooling(features).view(features.size(0), -1)\n",
    "        \n",
    "        # --- 2. Pass features through the *trainable* head ---\n",
    "        # Gradients will be computed for this part\n",
    "        embedding = self.embedding_head(pooled)\n",
    "        return embedding\n",
    "\n",
    "# --- 2. Data Transforms ---\n",
    "def get_transforms():\n",
    "    \"\"\"\n",
    "    Returns the correct transforms for training and evaluation.\n",
    "    This includes the specific normalization for torchxrayvision models.\n",
    "    \"\"\"\n",
    "    # This is the normalization specified by torchxrayvision\n",
    "    XRV_MEAN = [0.5081]\n",
    "    XRV_STD = [0.0893]\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=1), # Ensure 1-channel\n",
    "        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=XRV_MEAN, std=XRV_STD)\n",
    "    ])\n",
    "    \n",
    "    # Test transform does not have data augmentation\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=XRV_MEAN, std=XRV_STD)\n",
    "    ])\n",
    "\n",
    "    return train_transform, test_transform\n",
    "\n",
    "# --- 3. Episodic Sampler (The \"Loader Fix\") ---\n",
    "class EpisodicBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Sampler to create episodic batches.\n",
    "    This is the correct way to fix your broken data loading loop.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_targets, n_way, n_shot, n_query, episodes_per_epoch):\n",
    "        super().__init__(data_targets)\n",
    "        self.data_targets = data_targets\n",
    "        self.n_way = n_way\n",
    "        self.n_shot = n_shot\n",
    "        self.n_query = n_query\n",
    "        self.episodes_per_epoch = episodes_per_epoch\n",
    "\n",
    "        # Create a dict of {class: [list of image indices]}\n",
    "        self.class_indices = {}\n",
    "        for idx, target in enumerate(self.data_targets):\n",
    "            if target not in self.class_indices:\n",
    "                self.class_indices[target] = []\n",
    "            self.class_indices[target].append(idx)\n",
    "            \n",
    "        self.classes = list(self.class_indices.keys())\n",
    "        \n",
    "        if self.n_way > len(self.classes):\n",
    "            raise ValueError(f\"N_WAY ({self.n_way}) cannot be larger than the number of available classes ({len(self.classes)})\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.episodes_per_epoch\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.episodes_per_epoch):\n",
    "            episode_indices = []\n",
    "            \n",
    "            # 1. Select N_WAY classes at random\n",
    "            try:\n",
    "                selected_classes = np.random.choice(self.classes, self.n_way, replace=False)\n",
    "            except ValueError:\n",
    "                print(\"Warning: Not enough classes to sample from. Check N_WAY.\")\n",
    "                continue\n",
    "\n",
    "            # 2. For each class, sample N_SHOT + N_QUERY images\n",
    "            for cls in selected_classes:\n",
    "                class_idx = self.class_indices[cls]\n",
    "                \n",
    "                # Check if we have enough samples, sample with replacement if not\n",
    "                replace = len(class_idx) < (self.n_shot + self.n_query)\n",
    "                \n",
    "                try:\n",
    "                    selected_idx = np.random.choice(class_idx, self.n_shot + self.n_query, replace=replace)\n",
    "                    episode_indices.extend(selected_idx)\n",
    "                except:\n",
    "                    # This handles a rare case where a class might have 0 images\n",
    "                    continue\n",
    "                    \n",
    "            if len(episode_indices) == self.n_way * (self.n_shot + self.n_query):\n",
    "                yield episode_indices\n",
    "            else:\n",
    "                # This can happen if a class failed to sample\n",
    "                # print(\"Skipping episode due to sample mismatch\")\n",
    "                continue\n",
    "\n",
    "\n",
    "# --- 4. Prototypical Loss and Accuracy ---\n",
    "def prototypical_loss(embeddings, labels, n_shot, n_query, n_way, device):\n",
    "    \"\"\"\n",
    "    A robust prototypical loss function.\n",
    "    Assumes batch is structured as [N_WAY * (N_SHOT + N_QUERY), EMBEDDING_DIM]\n",
    "    and labels are the original ImageFolder labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reshape embeddings: [N_WAY, N_SHOT + N_QUERY, EMBEDDING_DIM]\n",
    "    embeddings = embeddings.reshape(n_way, n_shot + n_query, -1)\n",
    "\n",
    "    # Split into support and query sets\n",
    "    support_embeddings = embeddings[:, :n_shot, :]\n",
    "    query_embeddings = embeddings[:, n_shot:, :,]\n",
    "    \n",
    "    # Calculate prototypes by averaging support embeddings\n",
    "    # [N_WAY, EMBEDDING_DIM]\n",
    "    prototypes = support_embeddings.mean(dim=1)\n",
    "\n",
    "    # Flatten query embeddings for cdist\n",
    "    # [N_WAY * N_QUERY, EMBEDDING_DIM]\n",
    "    query_embeddings = query_embeddings.reshape(n_way * n_query, -1)\n",
    "    \n",
    "    # Calculate euclidean distances\n",
    "    # [N_WAY * N_QUERY, N_WAY]\n",
    "    distances = torch.cdist(query_embeddings, prototypes)\n",
    "    \n",
    "    # Create target labels for the query set\n",
    "    # [0, 0, ..., 1, 1, ..., N_WAY-1, ...]\n",
    "    query_labels = torch.arange(n_way, device=device).repeat_interleave(n_query)\n",
    "\n",
    "    # Calculate cross-entropy loss on negative distances\n",
    "    # (using -distances makes it a \"similarity\" score)\n",
    "    loss = F.cross_entropy(-distances, query_labels)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    # Find the prototype with the minimum distance (closest match)\n",
    "    _, predicted_labels = torch.min(distances, dim=1)\n",
    "    accuracy = (predicted_labels == query_labels).float().mean()\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22a2b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Meta-Train (Base) dataset loaded.\n",
      "Found 100013 images in 2 classes.\n",
      "Classes: ['Normal', 'Pneumonia']\n",
      "\n",
      "Starting meta-training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 500/500 [30:49<00:00,  3.70s/it, acc=0.8206, loss=0.4323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Avg Loss: 0.4323 | Avg Acc: 0.8206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 500/500 [30:21<00:00,  3.64s/it, acc=0.8194, loss=0.4269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Avg Loss: 0.4269 | Avg Acc: 0.8194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 500/500 [29:23<00:00,  3.53s/it, acc=0.8229, loss=0.4175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Avg Loss: 0.4175 | Avg Acc: 0.8229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 500/500 [29:48<00:00,  3.58s/it, acc=0.8221, loss=0.4156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Avg Loss: 0.4156 | Avg Acc: 0.8221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 500/500 [29:40<00:00,  3.56s/it, acc=0.8295, loss=0.4106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Avg Loss: 0.4106 | Avg Acc: 0.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 500/500 [29:44<00:00,  3.57s/it, acc=0.8212, loss=0.4164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Avg Loss: 0.4164 | Avg Acc: 0.8212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 500/500 [30:15<00:00,  3.63s/it, acc=0.8251, loss=0.4126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Avg Loss: 0.4126 | Avg Acc: 0.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 500/500 [31:33<00:00,  3.79s/it, acc=0.8244, loss=0.4126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Avg Loss: 0.4126 | Avg Acc: 0.8244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 500/500 [31:24<00:00,  3.77s/it, acc=0.8210, loss=0.4147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Avg Loss: 0.4147 | Avg Acc: 0.8210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 500/500 [31:08<00:00,  3.74s/it, acc=0.8227, loss=0.4238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Avg Loss: 0.4238 | Avg Acc: 0.8227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 500/500 [31:02<00:00,  3.72s/it, acc=0.8267, loss=0.4076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Avg Loss: 0.4076 | Avg Acc: 0.8267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 500/500 [30:05<00:00,  3.61s/it, acc=0.8245, loss=0.4128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Avg Loss: 0.4128 | Avg Acc: 0.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 500/500 [29:57<00:00,  3.59s/it, acc=0.8256, loss=0.4145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Avg Loss: 0.4145 | Avg Acc: 0.8256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 500/500 [29:38<00:00,  3.56s/it, acc=0.8250, loss=0.4108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Avg Loss: 0.4108 | Avg Acc: 0.8250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 500/500 [29:39<00:00,  3.56s/it, acc=0.8246, loss=0.4140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Avg Loss: 0.4140 | Avg Acc: 0.8246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 500/500 [29:48<00:00,  3.58s/it, acc=0.8208, loss=0.4154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Avg Loss: 0.4154 | Avg Acc: 0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 500/500 [29:33<00:00,  3.55s/it, acc=0.8221, loss=0.4201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Avg Loss: 0.4201 | Avg Acc: 0.8221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 500/500 [29:23<00:00,  3.53s/it, acc=0.8308, loss=0.4119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Avg Loss: 0.4119 | Avg Acc: 0.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 500/500 [29:25<00:00,  3.53s/it, acc=0.8247, loss=0.4103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Avg Loss: 0.4103 | Avg Acc: 0.8247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 500/500 [29:48<00:00,  3.58s/it, acc=0.8284, loss=0.4116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Avg Loss: 0.4116 | Avg Acc: 0.8284\n",
      "\n",
      "Meta-training complete. Model saved to fsl_backbone.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchxrayvision as xrv\n",
    "import numpy as np\n",
    "\n",
    "# --- Setup Hyperparameters ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Data and Model\n",
    "META_TRAIN_DIR = 'fsl_data/meta_train'\n",
    "MODEL_SAVE_PATH = 'fsl_backbone.pth'\n",
    "\n",
    "# FSL parameters\n",
    "N_WAY = 2  # 2 base classes (Normal, Pneumonia)\n",
    "N_SHOT = 10 # 10 support images per class\n",
    "N_QUERY = 10 # 10 query images per class\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 20\n",
    "EPISODES_PER_EPOCH = 500\n",
    "LEARNING_RATE = 0.0001 # Use a small LR for fine-tuning\n",
    "\n",
    "# --- 3. Load Data ---\n",
    "train_transform, _ = get_transforms()\n",
    "train_dataset = ImageFolder(META_TRAIN_DIR, transform=train_transform)\n",
    "\n",
    "print(f\"\\nMeta-Train (Base) dataset loaded.\")\n",
    "print(f\"Found {len(train_dataset)} images in {len(train_dataset.classes)} classes.\")\n",
    "print(f\"Classes: {train_dataset.classes}\")\n",
    "\n",
    "# Create the Episodic Sampler\n",
    "train_sampler = EpisodicBatchSampler(\n",
    "    train_dataset.targets, \n",
    "    N_WAY, N_SHOT, N_QUERY, \n",
    "    EPISODES_PER_EPOCH\n",
    ")\n",
    "\n",
    "# Create the DataLoader\n",
    "# IMPORTANT: batch_size=None tells the loader to use our custom batch sampler\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_sampler=train_sampler,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# --- 4. Initialize Model and Optimizer ---\n",
    "model = PrototypicalNet().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- 5. Main Meta-Training Loop ---\n",
    "print(\"\\nStarting meta-training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    \n",
    "    # Use tqdm for a progress bar\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\") as pbar:\n",
    "        for batch in pbar:\n",
    "            images, labels = batch\n",
    "            images = images.to(DEVICE)\n",
    "            \n",
    "            # 1. Get embeddings from the model\n",
    "            embeddings = model(images)\n",
    "            \n",
    "            # 2. Calculate loss and accuracy\n",
    "            loss, acc = prototypical_loss(\n",
    "                embeddings, labels, \n",
    "                N_SHOT, N_QUERY, N_WAY, \n",
    "                DEVICE\n",
    "            )\n",
    "            \n",
    "            # 3. Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(\n",
    "                loss=f\"{total_loss / (pbar.n + 1):.4f}\", \n",
    "                acc=f\"{total_acc / (pbar.n + 1):.4f}\"\n",
    "            )\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_acc = total_acc / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} Avg Loss: {avg_loss:.4f} | Avg Acc: {avg_acc:.4f}\")\n",
    "\n",
    "# --- 6. Save the Trained Model ---\n",
    "# We save the state_dict of the meta-trained model\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"\\nMeta-training complete. Model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da83aef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Meta-Test (Novel) dataset loaded.\n",
      "Found 4316 images in 2 classes.\n",
      "Classes: ['COVID', 'Tuberculosis']\n",
      "Successfully loaded pre-trained model from C:\\Users\\SUBRAT\\MAFSL PROJECT\\fsl_backbone.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Meta-Test: 100%|██████████| 1000/1000 [1:02:46<00:00,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "--- Meta-Test Results ---\n",
      "Task: 2-way, 10-shot (COVID vs TB)\n",
      "Episodes Run: 1000\n",
      "Average Loss: 0.6689\n",
      "Average Accuracy: 61.43%\n",
      "95% Confidence Interval: +/- 0.65%\n",
      "==============================\n",
      "Final Reported Accuracy: 61.43 ± 0.65%\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- TESTING ON NOVEL CLASSES ---\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Data and Model\n",
    "META_TEST_DIR = 'fsl_data/meta_test'\n",
    "MODEL_PATH = r'C:\\Users\\SUBRAT\\MAFSL PROJECT\\fsl_backbone.pth' # Load the model we just trained\n",
    "\n",
    "# FSL parameters for testing\n",
    "# We are testing on 2 *novel* classes (COVID, TB)\n",
    "N_WAY = 2  \n",
    "# We will test on 5-shot\n",
    "N_SHOT = 10 \n",
    "N_QUERY = 15 # Use more query images for a stable evaluation\n",
    "\n",
    "# Evaluation parameters\n",
    "TEST_EPISODES = 1000 # Run 1000 test episodes for a good average\n",
    "\n",
    "# --- 3. Load Data ---\n",
    "_, test_transform = get_transforms() # Use the test transform (no augmentation)\n",
    "test_dataset = ImageFolder(META_TEST_DIR, transform=test_transform)\n",
    "\n",
    "print(f\"\\nMeta-Test (Novel) dataset loaded.\")\n",
    "print(f\"Found {len(test_dataset)} images in {len(test_dataset.classes)} classes.\")\n",
    "print(f\"Classes: {test_dataset.classes}\")\n",
    "\n",
    "# Create the Episodic Sampler\n",
    "test_sampler = EpisodicBatchSampler(\n",
    "    data_targets=test_dataset.targets,\n",
    "    n_way=N_WAY,\n",
    "    n_shot=N_SHOT,\n",
    "    n_query=N_QUERY,\n",
    "    episodes_per_epoch=TEST_EPISODES\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# --- 4. Load Meta-Trained Model ---\n",
    "model = PrototypicalNet(out_dim=256).to(DEVICE)\n",
    "try:\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "    print(f\"Successfully loaded pre-trained model from {MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Please make sure 'meta_train.py' ran successfully and saved the model.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "total_loss = 0.0\n",
    "all_accuracies = [] # Store all 1000 accuracies\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (batch_images, batch_labels) in tqdm(test_loader, desc=\"Running Meta-Test\"):\n",
    "        batch_images = batch_images.to(DEVICE)\n",
    "        \n",
    "        embeddings = model(batch_images)\n",
    "        loss, accuracy = prototypical_loss(\n",
    "        embeddings, batch_labels, N_SHOT, N_QUERY, N_WAY, DEVICE )\n",
    "\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        all_accuracies.append(accuracy.item()) # Store each accuracy\n",
    "\n",
    "# --- Report Final Results (MODIFIED FOR CONFIDENCE INTERVAL) ---\n",
    "avg_loss = total_loss / TEST_EPISODES\n",
    "\n",
    "# Calculate final statistics\n",
    "avg_acc = np.mean(all_accuracies)\n",
    "std_dev = np.std(all_accuracies)\n",
    "\n",
    "# 95% confidence interval = 1.96 * (std / sqrt(n))\n",
    "# This is the \"+/-\" value\n",
    "confidence_interval = 1.96 * (std_dev / np.sqrt(len(all_accuracies)))\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"--- Meta-Test Results ---\")\n",
    "print(f\"Task: {N_WAY}-way, {N_SHOT}-shot (COVID vs TB)\")\n",
    "print(f\"Episodes Run: {len(all_accuracies)}\")\n",
    "print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_acc * 100:.2f}%\")\n",
    "print(f\"95% Confidence Interval: +/- {confidence_interval * 100:.2f}%\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Final Reported Accuracy: {avg_acc * 100:.2f} ± {confidence_interval * 100:.2f}%\")\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80dfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
