{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889632a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchxrayvision as xrv\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c444301",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- 1. Model Definition (Hybrid w/ Transplanted Backbone) ---\n",
    "class PrototypicalNet(nn.Module):\n",
    "    def __init__(self, out_dim=256): \n",
    "        super(PrototypicalNet, self).__init__()\n",
    "        \n",
    "        # A. Load the default backbone structure\n",
    "        model = xrv.models.DenseNet(weights=\"densenet121-res224-all\")\n",
    "        self.backbone = model.features\n",
    "        \n",
    "        # B. Load the \"smarter\" weights from our 86% F1-score model\n",
    "        try:\n",
    "            backbone_weights = torch.load('finetuned_backbone_from_imbalanced_model.pth')\n",
    "            self.backbone.load_state_dict(backbone_weights)\n",
    "            print(\"Successfully loaded fine-tuned backbone from imbalanced model.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load fine-tuned backbone. Using default weights. Error: {e}\")\n",
    "\n",
    "        # C. Freeze the (now smarter) backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # D. Add the trainable embedding head\n",
    "        self.embedding_head = nn.Linear(1024, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad(): \n",
    "            features = self.backbone(x)\n",
    "        pooled = self.pooling(features).view(features.size(0), -1)\n",
    "        embedding = self.embedding_head(pooled)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb30121a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- 2. Data Transforms (Same as before) ---\n",
    "def get_transforms():\n",
    "    XRV_MEAN = [0.5081]\n",
    "    XRV_STD = [0.0893]\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=XRV_MEAN, std=XRV_STD)\n",
    "    ])\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=XRV_MEAN, std=XRV_STD)\n",
    "    ])\n",
    "    return train_transform, test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdbfd05",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- 3. Episodic Sampler (Same as before) ---\n",
    "class EpisodicBatchSampler(Sampler):\n",
    "    def __init__(self, data_targets, n_way, n_shot, n_query, episodes_per_epoch):\n",
    "        super().__init__(data_targets)\n",
    "        self.data_targets = data_targets\n",
    "        self.n_way = n_way\n",
    "        self.n_shot = n_shot\n",
    "        self.n_query = n_query\n",
    "        self.episodes_per_epoch = episodes_per_epoch\n",
    "        self.class_indices = {}\n",
    "        for idx, target in enumerate(self.data_targets):\n",
    "            if target not in self.class_indices: self.class_indices[target] = []\n",
    "            self.class_indices[target].append(idx)\n",
    "        self.classes = list(self.class_indices.keys())\n",
    "        if self.n_way > len(self.classes):\n",
    "            raise ValueError(f\"N_WAY ({self.n_way}) cannot be larger than the number of available classes ({len(self.classes)})\")\n",
    "    def __len__(self):\n",
    "        return self.episodes_per_epoch\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.episodes_per_epoch):\n",
    "            episode_indices = []\n",
    "            try:\n",
    "                selected_classes = np.random.choice(self.classes, self.n_way, replace=False)\n",
    "            except ValueError: continue\n",
    "            for cls in selected_classes:\n",
    "                class_idx = self.class_indices[cls]\n",
    "                replace = len(class_idx) < (self.n_shot + self.n_query)\n",
    "                try:\n",
    "                    selected_idx = np.random.choice(class_idx, self.n_shot + self.n_query, replace=replace)\n",
    "                    episode_indices.extend(selected_idx)\n",
    "                except: continue\n",
    "            if len(episode_indices) == self.n_way * (self.n_shot + self.n_query):\n",
    "                yield episode_indices\n",
    "            else: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1129ae",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- 4. Prototypical Loss (UPDATED FOR COSINE SIMILARITY) ---\n",
    "def prototypical_loss(embeddings, labels, n_shot, n_query, n_way, device):\n",
    "    embeddings = embeddings.reshape(n_way, n_shot + n_query, -1)\n",
    "    support_embeddings = embeddings[:, :n_shot, :]\n",
    "    query_embeddings = embeddings[:, n_shot:, :,]\n",
    "    \n",
    "    prototypes = support_embeddings.mean(dim=1)\n",
    "    query_embeddings = query_embeddings.reshape(n_way * n_query, -1)\n",
    "    \n",
    "    # --- THIS IS THE KEY CHANGE ---\n",
    "    # Normalize vectors to unit length\n",
    "    query_embeddings_norm = F.normalize(query_embeddings, p=2, dim=1)\n",
    "    prototypes_norm = F.normalize(prototypes, p=2, dim=1)\n",
    "    \n",
    "    # Calculate cosine similarity (matrix multiplication)\n",
    "    # Higher similarity is better, so we use this directly as logits\n",
    "    similarities = torch.mm(query_embeddings_norm, prototypes_norm.t())\n",
    "    # --- END CHANGE ---\n",
    "\n",
    "    query_labels = torch.arange(n_way, device=device).repeat_interleave(n_query)\n",
    "\n",
    "    # Use similarities as logits for the loss\n",
    "    loss = F.cross_entropy(similarities, query_labels)\n",
    "    \n",
    "    # Calculate accuracy based on highest similarity\n",
    "    _, predicted_labels = torch.max(similarities, dim=1)\n",
    "    accuracy = (predicted_labels == query_labels).float().mean()\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de41e32",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- 5. Meta-Training Function (UPDATED) ---\n",
    "def run_meta_training():\n",
    "    print(\"--- Starting Meta-Training Phase (with Cosine Similarity) ---\")\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    META_TRAIN_DIR = 'fsl_data/meta_train'\n",
    "    MODEL_SAVE_PATH = 'fsl_backbone_cosine.pth' # New save path\n",
    "    N_WAY = 2\n",
    "    N_SHOT = 10\n",
    "    N_QUERY = 10\n",
    "    EPOCHS = 20\n",
    "    EPISODES_PER_EPOCH = 500\n",
    "    LEARNING_RATE = 0.0001\n",
    "\n",
    "    train_transform, _ = get_transforms()\n",
    "    train_dataset = ImageFolder(META_TRAIN_DIR, transform=train_transform)\n",
    "\n",
    "    print(f\"\\nMeta-Train (Base) dataset loaded.\")\n",
    "    print(f\"Found {len(train_dataset)} images in {len(train_dataset.classes)} classes.\")\n",
    "    print(f\"Classes: {train_dataset.classes}\")\n",
    "\n",
    "    train_sampler = EpisodicBatchSampler(\n",
    "        train_dataset.targets, N_WAY, N_SHOT, N_QUERY, EPISODES_PER_EPOCH\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_sampler=train_sampler,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    model = PrototypicalNet().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    print(\"\\nStarting meta-training...\")\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        \n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\") as pbar:\n",
    "            for batch in pbar:\n",
    "                images, labels = batch\n",
    "                images = images.to(DEVICE)\n",
    "                \n",
    "                embeddings = model(images)\n",
    "                loss, acc = prototypical_loss(\n",
    "                    embeddings, labels, N_SHOT, N_QUERY, N_WAY, DEVICE\n",
    "                )\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_acc += acc.item()\n",
    "                \n",
    "                pbar.set_postfix(\n",
    "                    loss=f\"{total_loss / (pbar.n + 1):.4f}\", \n",
    "                    acc=f\"{total_acc / (pbar.n + 1):.4f}\"\n",
    "                )\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_acc = total_acc / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1} Avg Loss: {avg_loss:.4f} | Avg Acc: {avg_acc:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(f\"\\nMeta-training complete. Model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef06a1d4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# --- 6. Meta-Testing Function (UPDATED) ---\n",
    "def run_meta_testing():\n",
    "    print(\"\\n--- Starting Meta-Testing Phase (with Cosine Similarity) ---\")\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    META_TEST_DIR = 'fsl_data/meta_test'\n",
    "    MODEL_PATH = 'fsl_backbone_cosine.pth' # Load the new model\n",
    "    N_WAY = 2  \n",
    "    N_SHOT = 10 \n",
    "    N_QUERY = 15\n",
    "    TEST_EPISODES = 1000\n",
    "\n",
    "    _, test_transform = get_transforms()\n",
    "    test_dataset = ImageFolder(META_TEST_DIR, transform=test_transform)\n",
    "\n",
    "    print(f\"\\nMeta-Test (Novel) dataset loaded.\")\n",
    "    print(f\"Found {len(test_dataset)} images in {len(test_dataset.classes)} classes.\")\n",
    "    print(f\"Classes: {test_dataset.classes}\")\n",
    "\n",
    "    test_sampler = EpisodicBatchSampler(\n",
    "        data_targets=test_dataset.targets,\n",
    "        n_way=N_WAY,\n",
    "        n_shot=N_SHOT,\n",
    "        n_query=N_QUERY,\n",
    "        episodes_per_epoch=TEST_EPISODES\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_sampler=test_sampler,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    model = PrototypicalNet(out_dim=256).to(DEVICE)\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "        print(f\"Successfully loaded pre-trained model from {MODEL_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_accuracies = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (batch_images, batch_labels) in tqdm(test_loader, desc=\"Running Meta-Test\"):\n",
    "            batch_images = batch_images.to(DEVICE)\n",
    "            \n",
    "            embeddings = model(batch_images)\n",
    "            loss, accuracy = prototypical_loss(\n",
    "                embeddings, batch_labels, N_SHOT, N_QUERY, N_WAY, DEVICE\n",
    "            )\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_accuracies.append(accuracy.item())\n",
    "\n",
    "    avg_loss = total_loss / TEST_EPISODES\n",
    "    avg_acc = np.mean(all_accuracies)\n",
    "    std_dev = np.std(all_accuracies)\n",
    "    confidence_interval = 1.96 * (std_dev / np.sqrt(len(all_accuracies)))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"--- Meta-Test Results ---\")\n",
    "    print(f\"Task: {N_WAY}-way, {N_SHOT}-shot (COVID vs TB)\")\n",
    "    print(f\"Episodes Run: {len(all_accuracies)}\")\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Average Accuracy: {avg_acc * 100:.2f}%\")\n",
    "    print(f\"95% Confidence Interval: +/- {confidence_interval * 100:.2f}%\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Final Reported Accuracy: {avg_acc * 100:.2f} Â± {confidence_interval * 100:.2f}%\")\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    run_meta_training()\n",
    "    run_meta_testing()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
